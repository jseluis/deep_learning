{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3932,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import misc\n",
    "import glob\n",
    "import warnings\n",
    "np.random.seed(1)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3431,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1,1],[3,4],[5,5],[9,7],[6,4],[4,4],[10,1],[1,3]]) \n",
    "Y_train = np.array([[1,0,0],[0,1,0],[1,0,0],[0,0,1],[0,0,1],[1,0,0],[0,0,1],[0,1,0]])\n",
    "X_test = np.array([[3,3],[3,10],[1,5],[12,12],[2,2]])\n",
    "Y_test = np.array([[1,0,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3593,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    # Loads the MNIST dataset from png images\n",
    " \n",
    "    NUM_LABELS = 10        \n",
    "    # create list of image objects\n",
    "    test_images = []\n",
    "    test_labels = []    \n",
    "    \n",
    "    for label in range(NUM_LABELS):\n",
    "        for image_path in glob.glob(\"MNIST/Test/\" + str(label) + \"/*.png\"):\n",
    "            image = misc.imread(image_path)\n",
    "            test_images.append(image)\n",
    "            letter = [0 for _ in range(0,NUM_LABELS)]    \n",
    "            letter[label] = 1\n",
    "            test_labels.append(letter)  \n",
    "            \n",
    "    # create list of image objects\n",
    "    train_images = []\n",
    "    train_labels = []    \n",
    "    \n",
    "    for label in range(NUM_LABELS):\n",
    "        for image_path in glob.glob(\"MNIST/Train/\" + str(label) + \"/*.png\"):\n",
    "            image = misc.imread(image_path)\n",
    "            train_images.append(image)\n",
    "            letter = [0 for _ in range(0,NUM_LABELS)]    \n",
    "            letter[label] = 1\n",
    "            train_labels.append(letter)                  \n",
    "            \n",
    "    X_train= np.array(train_images).reshape(-1,784)/255.0\n",
    "    Y_train= np.array(train_labels)\n",
    "    X_test= np.array(test_images).reshape(-1,784)/255.0\n",
    "    Y_test= np.array(test_labels)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3594,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(x_train,y_train):\n",
    "    jsneural.std_gaussian = 0.01\n",
    "    jsneural.alpha = -0.3\n",
    "    jsneural.epoch = 150\n",
    "    jsneural.batch_size = 100\n",
    "    jsneural.counter = 0\n",
    "    jsneural.n = x_train.shape[0]\n",
    "    jsneural.iterations=int(jsneural.n/jsneural.batch_size) # automated - based on the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4361,
   "metadata": {},
   "outputs": [],
   "source": [
    "class jsneural():\n",
    "    Count = 0\n",
    "    alpha = []\n",
    "    std_gaussian = []\n",
    "    epoch = []\n",
    "    batch_size = []\n",
    "    n = []\n",
    "    iterations = []\n",
    "    counter = 0\n",
    "    np.random.seed(10)\n",
    "    layers = {}\n",
    "    cost = []\n",
    "    cost_vector = []\n",
    "    \n",
    "    def __init__(self, input_x='False', output_y='False', n_nodes='False', activation='False'):\n",
    "        self.x_train = input_x\n",
    "        self.y_train = output_y\n",
    "        self.n_nodes = n_nodes\n",
    "        self.activation = activation\n",
    "        self.w=[]\n",
    "        self.b=[]\n",
    "        self.dw=[]\n",
    "        self.db=[]\n",
    "        self.H_term=[]\n",
    "        self.z=[]\n",
    "        self.h=[]\n",
    "        self.h_derivative=[]\n",
    "        jsneural.layers.update({jsneural.Count:'layer'+str(jsneural.Count)}) # Create dictionary for each layer\n",
    "        jsneural.Count += 1 # Every time a new object is defined\n",
    "        \n",
    " ########## Random parameters for the network ############\n",
    "\n",
    "    def add_random(self,x):\n",
    "        if (self.activation == \"softmax\"): # Generate matrix from previous layer (n_nodes)\n",
    "            #self.w = np.random.normal(size = ([eval('layer'+str(jsneural.Count-2)+'.n_nodes'),self.y_train.shape[1]]),loc=0,scale=jsneural.std_gaussian) \n",
    "            self.w = np.random.normal(size = ([eval(jsneural.layers[x]+'.n_nodes')\n",
    "                                               ,self.y_train.shape[1]]),loc=0,scale=jsneural.std_gaussian) \n",
    "            self.b = np.zeros([self.y_train.shape[1]])\n",
    "        else:\n",
    "            #self.w = np.random.normal(size = ([eval('layer'+str(x)+'.n_nodes'),self.n_nodes]),loc=0,scale=jsneural.std_gaussian) \n",
    "            self.w = np.random.normal(size = ([eval(jsneural.layers[x]+'.n_nodes')\n",
    "                                               ,self.n_nodes]),loc=0,scale=jsneural.std_gaussian) \n",
    "            self.b = np.zeros([self.n_nodes])\n",
    "  \n",
    "    def generate_parameters(): # Loop to generate parameters for all the systems\n",
    "        for i in range(jsneural.Count-1):\n",
    "            eval(jsneural.layers[i+1]+'.add_random('+str(i)+')') # Run over dictionary\n",
    "            #print(eval(jsneural.layers[i+1]+'.w')) debug ok\n",
    "            #eval('layer'+str(i+1)+'.add_random('+str(i)+')') debug ok\n",
    "            \n",
    " ##################################################\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.z = np.dot(x,self.w)+self.b\n",
    "        self.h = jsneural.sigma(self.z,activation=self.activation)\n",
    "        self.h_derivative = jsneural.activation_derivatives(self,activation=self.activation)\n",
    "    \n",
    "    def activation_derivatives(self,activation=False):\n",
    "        if (self.activation == \"sigmoid\"):\n",
    "            return self.h*(1-self.h) \n",
    "        elif (self.activation == \"relu\"):\n",
    "            return np.where(np.maximum(0.0, self.h)>0,1,0)    \n",
    "        else:\n",
    "            return []\n",
    "             \n",
    "    def L_model_forward(x_minibatch):\n",
    "        layer1.forward(x_minibatch)\n",
    "        for i in range(jsneural.Count-2):\n",
    "            eval('layer'+str(i+2)+'.forward(layer'+str(i+1)+'.h)')\n",
    "    \n",
    "    def update_parameters(self,dw,db):\n",
    "        self.w+=alpha*dw\n",
    "        self.b+=alpha*db\n",
    "    \n",
    "    def parameters(self):\n",
    "        weight = self.w\n",
    "        bias = self.b\n",
    "        return weight,bias\n",
    "    \n",
    "    ## Activation functions\n",
    "    def sigma(z_i,activation=False):\n",
    "        if(activation==False):\n",
    "            return print('Please choose an activation function')\n",
    "        elif(activation=='sigmoid'):\n",
    "            p_ik = 1/(1+np.exp(-z_i))\n",
    "            return p_ik\n",
    "        elif(activation=='softmax'):\n",
    "            z_ik = np.exp(z_i)\n",
    "            sum_row=np.sum(z_ik,axis=1).reshape(-1,1)\n",
    "            p_ik=np.divide(z_ik,sum_row)\n",
    "            return p_ik\n",
    "        elif(activation=='relu'):\n",
    "            p_ik = np.maximum(0.0,z_i)\n",
    "            return p_ik\n",
    "        \n",
    "    def compute_cost(y_in,loss_function=False): # Calculate the loss and cost function using entering arrays\n",
    "        if(loss_function==False):\n",
    "            return print('Please choose a loss function')\n",
    "        elif(loss_function=='cross_entropy'):\n",
    "            h_in = eval(jsneural.layers[jsneural.Count-1]+'.h')\n",
    "            nb = y_in.shape[0]\n",
    "            loss_calc = -np.sum(y_in*np.log(h_in),axis=1)\n",
    "            jsneural.cost = (1/nb)*np.sum(loss_calc)\n",
    "            return jsneural.cost\n",
    "    \n",
    "    def softmax_backward(self,p_in,x_in,y_in):\n",
    "        n_in = y_in.shape[0]\n",
    "        self.H_term = p_in - y_in\n",
    "        self.db = (1/n_in)*np.sum(self.H_term,axis=0)\n",
    "        self.dw = (1/n_in)*np.dot(np.transpose(x_in),self.H_term) # vector dJ/dW_j to update w_j for softmax\n",
    "    \n",
    "    def linear_backward(self,j,n_in):\n",
    "        #print(' activation =',self.activation,'; layer =',j) #debugged - passed attributes\n",
    "        H_next_layer = eval(jsneural.layers[j+1]+'.H_term')\n",
    "        w_next_layer = eval(jsneural.layers[j+1]+'.w')\n",
    "        H_previous_layer = eval(jsneural.layers[j-1]+'.h')\n",
    "        HwT = np.dot(H_next_layer,w_next_layer.T)\n",
    "        self.H_term = np.multiply(self.h_derivative,HwT) # memorization of commom term to backpropagate\n",
    "        self.db = (1/n_in)*np.sum(self.H_term,axis=0)\n",
    "        self.dw = (1/n_in)*np.matmul(H_previous_layer.T,self.H_term)\n",
    "        \n",
    "    def L_model_backward(x_back,y_back):     \n",
    "        layer0.h = x_back\n",
    "        n_in = y_back.shape[0]\n",
    "        h_L=eval(jsneural.layers[jsneural.Count-1]+'.h')\n",
    "        h_L_previous=eval(jsneural.layers[jsneural.Count-2]+'.h')\n",
    "        eval(jsneural.layers[jsneural.Count-1]+'.softmax_backward(h_L,h_L_previous,y_back)')\n",
    "        \n",
    "        for i in range(jsneural.Count-2,0,-1): # Generalization for all layers - ok\n",
    "            eval(jsneural.layers[i]+'.linear_backward(i,n_in)') #\n",
    "    \n",
    "    def update_parameters(self):\n",
    "        self.w += jsneural.alpha*self.dw\n",
    "        self.b += jsneural.alpha*self.db\n",
    "        \n",
    "    def L_model_update_parameters():\n",
    "        for k in range(jsneural.Count-1,0,-1):\n",
    "            eval(jsneural.layers[k]+'.update_parameters()')\n",
    "            \n",
    "    def random_mini_batches(x_in,y_in):\n",
    "        random_index = np.random.choice(x_in.shape[0],size = x_in.shape[0], replace= False)\n",
    "        x_out = x_in[random_index]\n",
    "        y_out = y_in[random_index]\n",
    "        return x_out,y_out\n",
    "\n",
    "    def train_L_layer_model(X_train,Y_train,loss_function=False):\n",
    "        jsneural.counter=0\n",
    "        for E in range(jsneural.epoch):\n",
    "            X_train_minibatch,Y_train_minibatch = jsneural.random_mini_batches(X_train,Y_train)\n",
    "            for i in range(jsneural.iterations):     \n",
    "                x_loop = X_train_minibatch[i*batch_size:(i+1)*batch_size,:]\n",
    "                y_loop = Y_train_minibatch[i*batch_size:(i+1)*batch_size,:]\n",
    "                \n",
    "                jsneural.L_model_forward(x_loop)\n",
    "                jsneural.compute_cost(y_loop,loss_function) # update jsneural.cost\n",
    "                jsneural.cost_vector.append(jsneural.cost)\n",
    "                jsneural.L_model_backward(x_loop,y_loop)\n",
    "                jsneural.L_model_update_parameters()\n",
    "                \n",
    "                jsneural.counter+=1\n",
    "            print('Epoch =',E,'; Cost Function =',jsneural.cost,'\\n')\n",
    "        print('Number of iterations = ',jsneural.counter)\n",
    "        \n",
    "    def prediction(xx,yy):\n",
    "        z = np.dot(xx,layer1.w)+layer1.b\n",
    "        h = jsneural.sigma(z,activation=layer1.activation)\n",
    "        for k in range(jsneural.Count-2):\n",
    "            print(k)\n",
    "            w_layer = eval('layer'+str(k+2)+'.w')\n",
    "            b_layer = eval('layer'+str(k+2)+'.b')\n",
    "            act = eval('layer'+str(k+2)+'.activation')\n",
    "            z = np.dot(h,w_layer)+b_layer\n",
    "            h = jsneural.sigma(z,activation=act)\n",
    "        h_max_acc = np.max(h,axis=1).reshape(-1,1)\n",
    "        y_pred=np.where(h>=h_max_acc,1,0)\n",
    "        acc = np.mean(y_pred == yy)\n",
    "        return acc,y_pred\n",
    "       \n",
    "    def update_layer(self, input_x='False', output_y='False', n_nodes='False', activation='False'):\n",
    "        self.x_train = input_x\n",
    "        self.y_train = output_y\n",
    "        self.n_nodes = n_nodes\n",
    "        self.activation = activation\n",
    "        self.w=[]\n",
    "        self.b=[]\n",
    "        self.z=[]\n",
    "        self.h=[]\n",
    "        jsneural.layers.update({jsneural.Count:'layer'+str(jsneural.Count)}) # Create dictionary for each layer\n",
    "        jsneural.Count = jsneural.Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4362,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize(X_train,Y_train)\n",
    "#print(n,alpha,epoch,batch_size,counter,iterations) # debug ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4363,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = jsneural(input_x=X_train,n_nodes=784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4364,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = jsneural(n_nodes=100,activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4365,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = jsneural(n_nodes=30,activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4366,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer3 = jsneural(output_y=Y_train,activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4367,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsneural.generate_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 ; Cost Function = 2.5010128570965304 \n",
      "\n",
      "Epoch = 1 ; Cost Function = 1.209916598903537 \n",
      "\n",
      "Epoch = 2 ; Cost Function = 2.104475374556428 \n",
      "\n",
      "Epoch = 3 ; Cost Function = 1.21619631716726 \n",
      "\n",
      "Epoch = 4 ; Cost Function = 0.7548127142139558 \n",
      "\n",
      "Epoch = 5 ; Cost Function = 0.9269182951068309 \n",
      "\n",
      "Epoch = 6 ; Cost Function = 0.33104597942861536 \n",
      "\n",
      "Epoch = 7 ; Cost Function = 0.06518395608257277 \n",
      "\n",
      "Epoch = 8 ; Cost Function = 0.09935786116411448 \n",
      "\n",
      "Epoch = 9 ; Cost Function = 0.2201516686870622 \n",
      "\n",
      "Epoch = 10 ; Cost Function = 1.0228296974071773 \n",
      "\n",
      "Epoch = 11 ; Cost Function = 0.346733315875038 \n",
      "\n",
      "Epoch = 12 ; Cost Function = 1.1794317868769992 \n",
      "\n",
      "Epoch = 13 ; Cost Function = 0.3410535197738852 \n",
      "\n",
      "Epoch = 14 ; Cost Function = 0.022800771639004687 \n",
      "\n",
      "Epoch = 15 ; Cost Function = 0.007424387379353625 \n",
      "\n",
      "Epoch = 16 ; Cost Function = 0.00597937332761329 \n",
      "\n",
      "Epoch = 17 ; Cost Function = 0.16729945356293718 \n",
      "\n",
      "Epoch = 18 ; Cost Function = 0.00785926003162146 \n",
      "\n",
      "Epoch = 19 ; Cost Function = 0.5922344361604638 \n",
      "\n",
      "Epoch = 20 ; Cost Function = 0.06275438110282966 \n",
      "\n",
      "Epoch = 21 ; Cost Function = 0.011020911253393077 \n",
      "\n",
      "Epoch = 22 ; Cost Function = 0.007690699714666712 \n",
      "\n",
      "Epoch = 23 ; Cost Function = 0.02249272637984801 \n",
      "\n",
      "Epoch = 24 ; Cost Function = 0.018543284640743056 \n",
      "\n",
      "Epoch = 25 ; Cost Function = 0.18817156665980408 \n",
      "\n",
      "Epoch = 26 ; Cost Function = 0.03051686530330934 \n",
      "\n",
      "Epoch = 27 ; Cost Function = 0.004477621508787938 \n",
      "\n",
      "Epoch = 28 ; Cost Function = 0.8616974360454779 \n",
      "\n",
      "Epoch = 29 ; Cost Function = 0.04078818125508956 \n",
      "\n",
      "Epoch = 30 ; Cost Function = 0.4089349465381221 \n",
      "\n",
      "Epoch = 31 ; Cost Function = 0.30973773852183106 \n",
      "\n",
      "Epoch = 32 ; Cost Function = 0.599862323534833 \n",
      "\n",
      "Epoch = 33 ; Cost Function = 0.026091177844652945 \n",
      "\n",
      "Epoch = 34 ; Cost Function = 0.011558109403459886 \n",
      "\n",
      "Epoch = 35 ; Cost Function = 0.06865717445315614 \n",
      "\n",
      "Epoch = 36 ; Cost Function = 0.2332096974051321 \n",
      "\n",
      "Epoch = 37 ; Cost Function = 0.016261308381292448 \n",
      "\n",
      "Epoch = 38 ; Cost Function = 0.0017020383055317634 \n",
      "\n",
      "Epoch = 39 ; Cost Function = 0.05906796734431832 \n",
      "\n",
      "Epoch = 40 ; Cost Function = 0.020165139127953344 \n",
      "\n",
      "Epoch = 41 ; Cost Function = 0.006771927779757139 \n",
      "\n",
      "Epoch = 42 ; Cost Function = 0.003508650784296167 \n",
      "\n",
      "Epoch = 43 ; Cost Function = 0.08969437842292878 \n",
      "\n",
      "Epoch = 44 ; Cost Function = 0.5333897498247719 \n",
      "\n",
      "Epoch = 45 ; Cost Function = 0.18125004738528636 \n",
      "\n",
      "Epoch = 46 ; Cost Function = 0.01638150841439422 \n",
      "\n",
      "Epoch = 47 ; Cost Function = 0.008981348240276205 \n",
      "\n",
      "Epoch = 48 ; Cost Function = 0.005526044720119959 \n",
      "\n",
      "Epoch = 49 ; Cost Function = 0.0043453371376075125 \n",
      "\n",
      "Epoch = 50 ; Cost Function = 0.0488431135117551 \n",
      "\n",
      "Epoch = 51 ; Cost Function = 0.15765263349979547 \n",
      "\n",
      "Epoch = 52 ; Cost Function = 0.04062027556857739 \n",
      "\n",
      "Epoch = 53 ; Cost Function = 0.011131024786438626 \n",
      "\n",
      "Epoch = 54 ; Cost Function = 0.11352636439313489 \n",
      "\n",
      "Epoch = 55 ; Cost Function = 0.022576817613268168 \n",
      "\n",
      "Epoch = 56 ; Cost Function = 0.06945265600117567 \n",
      "\n",
      "Epoch = 57 ; Cost Function = 0.0014464771785524383 \n",
      "\n",
      "Epoch = 58 ; Cost Function = 0.013474202037443869 \n",
      "\n",
      "Epoch = 59 ; Cost Function = 0.49771388028426417 \n",
      "\n",
      "Epoch = 60 ; Cost Function = 0.1812973831347132 \n",
      "\n",
      "Epoch = 61 ; Cost Function = 0.08633629043451894 \n",
      "\n",
      "Epoch = 62 ; Cost Function = 0.002682112688027232 \n",
      "\n",
      "Epoch = 63 ; Cost Function = 0.001935617559589115 \n",
      "\n",
      "Epoch = 64 ; Cost Function = 0.020984594174267398 \n",
      "\n",
      "Epoch = 65 ; Cost Function = 0.3906761191356873 \n",
      "\n",
      "Epoch = 66 ; Cost Function = 0.007691739002623432 \n",
      "\n",
      "Epoch = 67 ; Cost Function = 0.0020277192621420575 \n",
      "\n",
      "Epoch = 68 ; Cost Function = 0.02175887452867897 \n",
      "\n",
      "Epoch = 69 ; Cost Function = 0.003953064874850019 \n",
      "\n",
      "Epoch = 70 ; Cost Function = 0.006439307569007914 \n",
      "\n",
      "Epoch = 71 ; Cost Function = 0.0039764767226888155 \n",
      "\n",
      "Epoch = 72 ; Cost Function = 0.0019546500480787654 \n",
      "\n",
      "Epoch = 73 ; Cost Function = 0.006431501561047984 \n",
      "\n",
      "Epoch = 74 ; Cost Function = 0.0004530514600962688 \n",
      "\n",
      "Epoch = 75 ; Cost Function = 0.0033609295112107776 \n",
      "\n",
      "Epoch = 76 ; Cost Function = 0.002753794939065181 \n",
      "\n",
      "Epoch = 77 ; Cost Function = 0.08500219832434242 \n",
      "\n",
      "Epoch = 78 ; Cost Function = 0.0026273474136656984 \n",
      "\n",
      "Epoch = 79 ; Cost Function = 0.005245066751828469 \n",
      "\n",
      "Epoch = 80 ; Cost Function = 0.0028363205199838067 \n",
      "\n",
      "Epoch = 81 ; Cost Function = 0.6447947767744291 \n",
      "\n",
      "Epoch = 82 ; Cost Function = 0.0013881032174083547 \n",
      "\n",
      "Epoch = 83 ; Cost Function = 0.0004798320613665525 \n",
      "\n",
      "Epoch = 84 ; Cost Function = 0.0022659457136468128 \n",
      "\n",
      "Epoch = 85 ; Cost Function = 0.001918766119225402 \n",
      "\n",
      "Epoch = 86 ; Cost Function = 0.02822265495690657 \n",
      "\n",
      "Epoch = 87 ; Cost Function = 0.00765382659909844 \n",
      "\n",
      "Epoch = 88 ; Cost Function = 0.007129465172616548 \n",
      "\n",
      "Epoch = 89 ; Cost Function = 0.0015267768212969112 \n",
      "\n",
      "Epoch = 90 ; Cost Function = 0.0007260897313891416 \n",
      "\n",
      "Epoch = 91 ; Cost Function = 0.11271462289519533 \n",
      "\n",
      "Epoch = 92 ; Cost Function = 0.004760509707036101 \n",
      "\n",
      "Epoch = 93 ; Cost Function = 0.03513008480671205 \n",
      "\n",
      "Epoch = 94 ; Cost Function = 0.0034817087802035216 \n",
      "\n",
      "Epoch = 95 ; Cost Function = 0.00224955481879992 \n",
      "\n",
      "Epoch = 96 ; Cost Function = 0.0041966641138222885 \n",
      "\n",
      "Epoch = 97 ; Cost Function = 0.40926937803906066 \n",
      "\n",
      "Epoch = 98 ; Cost Function = 0.3136916873400283 \n",
      "\n",
      "Epoch = 99 ; Cost Function = 0.014523429762765019 \n",
      "\n",
      "Epoch = 100 ; Cost Function = 0.002159117329722747 \n",
      "\n",
      "Epoch = 101 ; Cost Function = 0.0011212717431377465 \n",
      "\n",
      "Epoch = 102 ; Cost Function = 0.005607311128960693 \n",
      "\n",
      "Epoch = 103 ; Cost Function = 0.0683148846866942 \n",
      "\n",
      "Epoch = 104 ; Cost Function = 0.0050703300650623345 \n",
      "\n",
      "Epoch = 105 ; Cost Function = 0.013186768664870688 \n",
      "\n",
      "Epoch = 106 ; Cost Function = 0.002265031416727628 \n",
      "\n",
      "Epoch = 107 ; Cost Function = 0.00020628706619012438 \n",
      "\n",
      "Epoch = 108 ; Cost Function = 0.00225855563145065 \n",
      "\n",
      "Epoch = 109 ; Cost Function = 0.0035600907032042922 \n",
      "\n",
      "Epoch = 110 ; Cost Function = 0.007768031734858428 \n",
      "\n",
      "Epoch = 111 ; Cost Function = 0.06852704283200348 \n",
      "\n",
      "Epoch = 112 ; Cost Function = 0.19547386861521096 \n",
      "\n",
      "Epoch = 113 ; Cost Function = 0.006154039332798794 \n",
      "\n",
      "Epoch = 114 ; Cost Function = 0.6100493159760207 \n",
      "\n",
      "Epoch = 115 ; Cost Function = 0.030085902601565663 \n",
      "\n",
      "Epoch = 116 ; Cost Function = 0.01961819727879991 \n",
      "\n",
      "Epoch = 117 ; Cost Function = 0.06717430008281902 \n",
      "\n",
      "Epoch = 118 ; Cost Function = 0.007820373843294053 \n",
      "\n",
      "Epoch = 119 ; Cost Function = 0.005418303082406498 \n",
      "\n",
      "Epoch = 120 ; Cost Function = 0.00220372077171873 \n",
      "\n",
      "Epoch = 121 ; Cost Function = 0.1458013607707308 \n",
      "\n",
      "Epoch = 122 ; Cost Function = 0.003569465116250628 \n",
      "\n",
      "Epoch = 123 ; Cost Function = 2.8532440484573285 \n",
      "\n",
      "Epoch = 124 ; Cost Function = 0.001548774111595627 \n",
      "\n",
      "Epoch = 125 ; Cost Function = 0.0010048782302691337 \n",
      "\n",
      "Epoch = 126 ; Cost Function = 0.001610949869699322 \n",
      "\n",
      "Epoch = 127 ; Cost Function = 0.0011530250695816705 \n",
      "\n",
      "Epoch = 128 ; Cost Function = 0.0006289196642143602 \n",
      "\n",
      "Epoch = 129 ; Cost Function = 0.0007052185709153127 \n",
      "\n",
      "Epoch = 130 ; Cost Function = 0.1661823108374881 \n",
      "\n",
      "Epoch = 131 ; Cost Function = 0.0039278133355819716 \n",
      "\n",
      "Epoch = 132 ; Cost Function = 0.008330351594093803 \n",
      "\n",
      "Epoch = 133 ; Cost Function = 0.006087688667859094 \n",
      "\n",
      "Epoch = 134 ; Cost Function = 0.0016048554074946158 \n",
      "\n",
      "Epoch = 135 ; Cost Function = 0.0071250443101769 \n",
      "\n",
      "Epoch = 136 ; Cost Function = 0.003568491061168505 \n",
      "\n",
      "Epoch = 137 ; Cost Function = 0.011868639329613651 \n",
      "\n",
      "Epoch = 138 ; Cost Function = 0.07667702501079542 \n",
      "\n",
      "Epoch = 139 ; Cost Function = 0.0028960889726373992 \n",
      "\n",
      "Epoch = 140 ; Cost Function = 0.04500140339650722 \n",
      "\n",
      "Epoch = 141 ; Cost Function = 0.0011344393879014266 \n",
      "\n",
      "Epoch = 142 ; Cost Function = 0.6680508423165001 \n",
      "\n",
      "Epoch = 143 ; Cost Function = 0.006695269532939796 \n",
      "\n",
      "Epoch = 144 ; Cost Function = 0.004115750678647002 \n",
      "\n",
      "Epoch = 145 ; Cost Function = 0.00016865874658021271 \n",
      "\n",
      "Epoch = 146 ; Cost Function = 0.05249480705899943 \n",
      "\n",
      "Epoch = 147 ; Cost Function = 0.007613597470344444 \n",
      "\n",
      "Epoch = 148 ; Cost Function = 0.0017207071680737994 \n",
      "\n",
      "Epoch = 149 ; Cost Function = 0.0031845300637938292 \n",
      "\n",
      "Number of iterations =  90000\n"
     ]
    }
   ],
   "source": [
    "jsneural.train_L_layer_model(X_train,Y_train,loss_function='cross_entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 4375,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(1,jsneural.counter,jsneural.counter),jsneural.cost_vector)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_forward(xx,yy):\n",
    "    z = np.dot(xx,layer1.w)+layer1.b\n",
    "    h = jsneural.sigma(z,activation=layer1.activation)\n",
    "    for k in range(jsneural.Count-2):\n",
    "        w_layer = eval('layer'+str(k+2)+'.w')\n",
    "        b_layer = eval('layer'+str(k+2)+'.b')\n",
    "        act = eval('layer'+str(k+2)+'.activation')\n",
    "        z = np.dot(h,w_layer)+b_layer\n",
    "        h = jsneural.sigma(z,activation=act)\n",
    "    h_max_acc = np.max(h,axis=1).reshape(-1,1)\n",
    "    y_pred=np.where(h>=h_max_acc,1,0)\n",
    "    acc = np.mean(y_pred == yy)\n",
    "    return acc,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4386,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy,y_pred=prediction_forward(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99456"
      ]
     },
     "execution_count": 4389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
